# -*- coding: utf-8 -*-
"""7.Logistic_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VbuKNo6z3jS88uoZu3CPnBK-ftUBkVuy

## Importing the Required Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import StandardScaler,LabelEncoder
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

data=pd.read_csv("C:\\Users\\Admin\\Downloads\\Logistic Regression\\Logistic Regression\\Titanic_train.csv")

"""# EDA"""

data.head()

data.info()

data_1=data.drop(["Name","Sex","Ticket","Embarked","Cabin"],axis=1) #removing the categorical columns to check for correlation.

data_1.corr()

"""## Visualizations

Visualizations makes the data to understand better.We know that pictorial information makes the data understand better

### Heatmap
"""

sns.heatmap(data_1.corr(),annot=True)

pd.crosstab(data["Survived"],data["Sex"]).plot(kind="bar",stacked=True)

"""From the above plot, we can understand Most of the survived people are female"""

pd.crosstab(data["Survived"],data["Pclass"]).plot(kind="bar",stacked=True)

"""Most of the unsurvived people are from third class."""

pd.crosstab(data["Survived"],data["SibSp"]).plot(kind="bar",stacked=True)

pd.crosstab(data["Survived"],data["Parch"]).plot(kind="bar",stacked=True)

pd.crosstab(data["Survived"],data["Embarked"]).plot(kind="bar")

data["Embarked"].value_counts().plot(kind="pie",autopct="%1.1f%%")

data["Survived"].value_counts().plot(kind="pie",autopct="%1.1f%%")

data["Sex"].value_counts().plot(kind="pie",autopct="%1.1f%%")

"""Males are more than females in the Titanic ship"""

sns.histplot(data["Age"],facecolor="red")

sns.stripplot(x="Survived",y="Age",hue="Sex",data=data)

sns.stripplot(x="Survived",y="Age",hue="Pclass",data=data)

sns.stripplot(x="Survived",y="PassengerId",data=data)

sns.stripplot(x="Survived",y="Fare",hue="Sex",data=data)

data["Cabin"].value_counts()

"""From the above plots,some columns are not making any value to predict the survival.we are removing those columns to get the better model."""

data.drop(["PassengerId","Name","Ticket","Cabin"],axis=1,inplace=True)

data.info()

"""### Checking for Null values"""

data.isnull().sum()

sns.histplot(data["Age"])

data["Age"]

data["Age"].mean()

data["Age"].median()

""" Imputing the null values with median.All of the age values are natural numbers.So instead of filling with mean value,we are filling with median value."""

data["Age"].fillna(data["Age"].median(),inplace=True)

data["Embarked"].fillna(data["Embarked"].mode()[0],inplace=True)  #filling embarked null values with most frequent value

data.isnull().sum().sum()  #All Null values are imputed

data[data.duplicated(keep=False)]  #checking for duplicate values

data.drop_duplicates(keep="first",inplace=True) #removing the duplicate values

data.reset_index(drop=True,inplace=True)

data.describe()

"""## Detecting and Treating of Anamolies"""

plt.boxplot(data["Age"])

np.percentile(data.Age,[99])

a=np.percentile(data.Age,[99])[0]
a

data.Age[(data.Age>2*a)]=2*a

plt.boxplot(data["Fare"])

a=np.percentile(data.Fare,[99])[0]
a

data.Fare[(data.Fare>2*a)]=2*a

data.info()

"""## Label Encoding"""

data["Sex"]=LabelEncoder().fit_transform(data["Sex"])

data["Embarked"]=LabelEncoder().fit_transform(data["Embarked"])

"""## Standardization"""

scale=StandardScaler()
data["Age"]=scale.fit_transform(data[["Age"]])
data["Fare"]=scale.fit_transform(data[["Fare"]])

data

"""## Splitting the data into Train and test set"""

y=data.iloc[:,0]
x=data.iloc[:,1:]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=36)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

"""## Applying the Logistic Regression Model"""

model=LogisticRegression()
model.fit(x_train,y_train)

y_pred=model.predict(x_test)
y_prob =model.predict_proba(x_test)[:, 1]

"""## Evaluating the model"""

accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

"""Accuracy score we got was 83 which is better to predict the data.

## Interpreting the Coefficients
"""

x_train.columns

model.coef_

"""The columns Pclass,sex and age are the most important features and these three are making more contribution to find the survival probability.

## ROC Curve
"""

from sklearn.metrics import roc_curve
fpr,tpr,threshold=roc_curve(y,model.predict_proba(x)[:,1])
plt.plot(fpr,tpr,color="violet")
plt.plot([0,1],[0,1],"k--")
plt.xlabel("False Positive Rate or 1 - True Negative Rate")
plt.ylabel("True Positive Rate")
plt.show()

"""# Deployment with Streamlit"""

import streamlit as st
import pickle
import numpy as np

# Define the Streamlit app
st.title('Titanic Survival Prediction')
st.write('This app predicts the probability of surviving the Titanic disaster.')

# User input features
pclass = st.selectbox('Passenger Class', [1, 2, 3])
sex = st.selectbox('Sex', ['male', 'female'])
age = st.slider('Age', 0, 80, 30)
sibsp = st.number_input('Number of Siblings/Spouses Aboard', 0, 8, 0)
parch = st.number_input('Number of Parents/Children Aboard', 0, 6, 0)
fare = st.slider('Fare', 0.0, 500.0, 32.0)
embarked = st.selectbox('Port of Embarkation', ['Cherbourg', 'Queenstown', 'Southampton'])

# Encode categorical inputs
sex = 1 if sex == 'male' else 0
embarked_dict = {'Cherbourg': 0, 'Queenstown': 1, 'Southampton': 2}
embarked = embarked_dict[embarked]

# Prediction
features = np.array([[pclass, sex, age, sibsp, parch, fare, embarked]])
prediction = model.predict(features)[0]
probability = model.predict_proba(features)[0][1]

# Output prediction
if prediction == 1:
    st.write(f'The model predicts that the passenger survived with a probability of {probability:.2f}.')
else:
    st.write(f'The model predicts that the passenger did not survive with a probability of {1 - probability:.2f}.')

